import cv2
import os
import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨ Agg å¾Œç«¯é¿å… GUI å•é¡Œ
import matplotlib.pyplot as plt
import shutil

import csv
import sys
import numpy as np
import tensorflow as tf
import tqdm

pose_sample_rpi_path = os.path.join(os.getcwd(), 'examples/lite/examples/pose_estimation/raspberry_pi')
sys.path.append(pose_sample_rpi_path)
import utils
from data import BodyPart
from ml import Movenet

movenet = Movenet('movenet_thunder')
def detect(input_tensor, inference_count=3):
  """Runs detection on an input image.
 
  Args:
    input_tensor: A [height, width, 3] Tensor of type tf.float32.
      Note that height and width can be anything since the image will be
      immediately resized according to the needs of the model within this
      function.
    inference_count: Number of times the model should run repeatly on the
      same input image to improve detection accuracy.
 
  Returns:
    A Person entity detected by the MoveNet.SinglePose.
  """
  image_height, image_width, channel = input_tensor.shape
 
  # Detect pose using the full input image
  movenet.detect(input_tensor.numpy(), reset_crop_region=True)
 
  # Repeatedly using previous detection result to identify the region of
  # interest and only croping that region to improve detection accuracy
  for _ in range(inference_count - 1):
    person = movenet.detect(input_tensor.numpy(), 
                            reset_crop_region=False)

  return person

def draw_prediction_on_image(
    image, person, crop_region=None, close_figure=True,
    keep_input_size=False):
  """Draws the keypoint predictions on image.
 
  Args:
    image: An numpy array with shape [height, width, channel] representing the
      pixel values of the input image.
    person: A person entity returned from the MoveNet.SinglePose model.
    close_figure: Whether to close the plt figure after the function returns.
    keep_input_size: Whether to keep the size of the input image.
 
  Returns:
    An numpy array with shape [out_height, out_width, channel] representing the
    image overlaid with keypoint predictions.
  """
  # Draw the detection result on top of the image.
  image_np = utils.visualize(image, [person])
  
  # Plot the image with detection results.
  height, width, channel = image.shape
  aspect_ratio = float(width) / height
  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))
  im = ax.imshow(image_np)
 
  if close_figure:
    plt.close(fig)
 
  if not keep_input_size:
    image_np = utils.keep_aspect_ratio_resizer(image_np, (512, 512))

  return image_np
class MoveNetPreprocessor(object):
    """Simplified MoveNet Preprocessor without subfolders."""

    def __init__(self, images_in_folder, images_out_folder, csvs_out_path):
        """
        Args:
            images_in_folder: å­˜æ”¾è¼¸å…¥åœ–ç‰‡çš„è³‡æ–™å¤¾ã€‚
            images_out_folder: å­˜æ”¾åµæ¸¬å¾Œåœ–ç‰‡çš„è³‡æ–™å¤¾ã€‚
            csvs_out_path: å­˜æ”¾é—œç¯€é»è³‡æ–™çš„ CSV æª”æ¡ˆè·¯å¾‘ã€‚
        """
        if not os.path.exists(images_in_folder):
            os.makedirs(images_in_folder)

        self._images_in_folder = images_in_folder
        self._images_out_folder = images_out_folder
        self._csvs_out_path = csvs_out_path
        self._messages = []

        os.makedirs(self._images_out_folder, exist_ok=True)
        os.makedirs(os.path.dirname(self._csvs_out_path), exist_ok=True)

        # å–å¾—æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆåç¨± (.jpg, .png)


    def process(self, detection_threshold=0.1):
        """è™•ç†æ‰€æœ‰åœ–ç‰‡ï¼Œé€²è¡Œå§¿å‹¢åµæ¸¬ä¸¦è¼¸å‡ºçµæœåˆ°åœ–ç‰‡å’Œ CSVã€‚"""
        print("ğŸš€ é–‹å§‹è™•ç†åœ–ç‰‡...")

        self._image_names = sorted([
            f for f in os.listdir(self._images_in_folder)
            if f.lower().endswith(('.jpg', '.jpeg', '.png')) and not f.startswith('.')
        ])
        # å»ºç«‹ CSV æª”æ¡ˆï¼Œå¯«å…¥è¡¨é ­
        with open(self._csvs_out_path, 'w', newline='') as csv_out_file:
            csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)

            # è¡¨é ­ï¼šfile_name + æ¯å€‹ keypoint çš„ (x, y, score)
            header = ["file_name"]
            for bodypart in BodyPart:
                header += [f"{bodypart.name}_x", f"{bodypart.name}_y", f"{bodypart.name}_score"]
            csv_out_writer.writerow(header)

            valid_image_count = 0

            # é€å¼µåœ–ç‰‡é€²è¡Œå§¿å‹¢åµæ¸¬
            for image_name in tqdm.tqdm(self._image_names):
                image_path = os.path.join(self._images_in_folder, image_name)

                # å˜—è©¦è®€å–åœ–ç‰‡
                try:
                    image = tf.io.read_file(image_path)
                    image = tf.io.decode_jpeg(image)
                except Exception as e:
                    self._messages.append(f"âŒ Skipped {image_path}. Error: {e}")
                    continue

                # æª¢æŸ¥æ˜¯å¦ç‚º RGB åœ–ç‰‡
                if image.shape[-1] != 3:
                    self._messages.append(f"âš ï¸ Skipped {image_path}. Not RGB.")
                    continue

                # å‘¼å«åµæ¸¬å‡½æ•¸
                person = detect(image)

                # æª¢æŸ¥ä¿¡å¿ƒåˆ†æ•¸
                min_landmark_score = min([k.score for k in person.keypoints])
                if min_landmark_score < detection_threshold:
                    self._messages.append(f"âš ï¸ Skipped {image_path}. Low confidence.")
                    continue

                valid_image_count += 1

                # ç¹ªè£½é—œç¯€é»
                output_overlay = draw_prediction_on_image(
                    image.numpy().astype(np.uint8),
                    person,
                    close_figure=True,
                    keep_input_size=True
                )
                output_frame = cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR)

                # å„²å­˜ç¹ªè£½å¾Œçš„åœ–ç‰‡
                # self._images_out_folder
                output_image_path = os.path.join(self._images_out_folder, image_name)
#                print(f"âœ… å·²å„²å­˜ç¹ªè£½å¾Œçš„åœ–ç‰‡: {self._images_out_folder}")
                cv2.imwrite(output_image_path, output_frame)
               

                # å–å‡º keypoint åº§æ¨™èˆ‡åˆ†æ•¸ï¼Œä¸¦å¯«å…¥ CSV
                pose_landmarks = np.array(
                    [[kp.coordinate.x, kp.coordinate.y, kp.score] for kp in person.keypoints],
                    dtype=np.float32
                )
                coordinates = pose_landmarks.flatten().astype(str).tolist()
                csv_out_writer.writerow([image_name] + coordinates)
            # 4ï¸âƒ£ è‡ªå‹•åˆªé™¤ temp_frames
        # if os.path.exists(self._images_in_folder):
        #     shutil.rmtree(self._images_in_folder)
        #     print(f"âœ… å·²è‡ªå‹•åˆªé™¤æš«å­˜è³‡æ–™å¤¾: {self._images_in_folder}")

        # çµæŸè¨Šæ¯
        if valid_image_count == 0:
            raise RuntimeError("âŒ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åœ–ç‰‡é€²è¡Œå§¿å‹¢åµæ¸¬ã€‚")
        else:
            print(f"âœ… è™•ç†å®Œæˆï¼Œå…±è™•ç† {valid_image_count} å¼µæœ‰æ•ˆåœ–ç‰‡ã€‚")

        if self._messages:
            print("\n".join(self._messages))



# å‡è¨­æœ‰å½±ç‰‡çš„ csv æª”æ¡ˆ (ç¶“é MoveNet è™•ç†å¾Œ)
def predict_from_csv(csv_path, model):
    import pandas as pd

    # è®€å– CSV ä¸¦è™•ç†è³‡æ–™
    df = pd.read_csv(csv_path)
    
    if "file_name" in df.columns:
        df.drop("file_name", axis=1, inplace=True)

    # èšåˆå¤šè¡Œæ•¸æ“š (å–å¹³å‡)
    feature_vector = df.min(axis=0).values.reshape(1, -1)
    # row_series = df_temp.max(axis=0)

    # é æ¸¬
    prediction = model.predict(feature_vector)
    return prediction[0]
def process_video_and_predict(video_path, model, temp_folder='temp_frames',output_csvs_path='output_csvs/output_data.csv', fps_extract=2):
    # 1. è½‰å½±ç‰‡ç‚ºå½±æ ¼
    if not os.path.exists(temp_folder):
        os.makedirs(temp_folder)

    cap = cv2.VideoCapture(video_path)
    video_fps = cap.get(cv2.CAP_PROP_FPS)
    frame_interval = int(video_fps / fps_extract)
    frame_count, extracted_count = 0, 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_interval == 0:
            frame_name = f"{extracted_count:06d}.jpg"
            cv2.imwrite(os.path.join(temp_folder, frame_name), frame)
            extracted_count += 1

        frame_count += 1

    cap.release()
    print(f"å·²æ“·å– {extracted_count} å¼µå½±æ ¼")

    # 2. ä½¿ç”¨ MoveNet è™•ç†å½±æ ¼ä¸¦è¼¸å‡º CSV
    # å‡è¨­æ­¤æ­¥é©Ÿå·²ç¶“å®Œæˆï¼Œä¸¦ç”Ÿæˆäº† `movenet_output.csv`
    preprocessor = MoveNetPreprocessor(
    # images_in_folder='temp_frames',        # è¼¸å…¥åœ–ç‰‡è³‡æ–™å¤¾
    images_in_folder=temp_folder,        # è¼¸å…¥åœ–ç‰‡è³‡æ–™å¤¾
    # images_out_folder='poses_images_out',   # åµæ¸¬å¾Œåœ–ç‰‡è¼¸å‡º
    images_out_folder=temp_folder,   # åµæ¸¬å¾Œåœ–ç‰‡è¼¸å‡º
    
    # csvs_out_path='output_csvs/output_data.csv'  # CSV è¼¸å‡º
     csvs_out_path=str(output_csvs_path) # CSV è¼¸
        )
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ MoveNetPreprocessor.process() ...")
    preprocessor.process()

    # 3. ä½¿ç”¨å·²è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œé æ¸¬
    csv_output_path = output_csvs_path  # å‡è¨­ MoveNet çš„çµæœ
    predicted_value = predict_from_csv(csv_output_path, model)
    print(f"å½±ç‰‡é æ¸¬çµæœ: {predicted_value}")
    return predicted_value

#è®€å–å½±ç‰‡
# video_path = "CAO,RUEI-LIAN(1).MOV"
video_path = "YANG,YI-RU(4).MOV"  

preprocessor = MoveNetPreprocessor(
    images_in_folder='temp_frames',        # è¼¸å…¥åœ–ç‰‡è³‡æ–™å¤¾
    images_out_folder='poses_images_out',   # åµæ¸¬å¾Œåœ–ç‰‡è¼¸å‡º
    csvs_out_path='output_csvs/output_data.csv'  # CSV è¼¸å‡º
)

import joblib

# å‡è¨­å·²è¨“ç·´å¥½çš„ model
model = LinearRegression()


# å„²å­˜æ¨¡å‹
model_save_path = "trained_model.joblib"

# è¼‰å…¥å„²å­˜çš„æ¨¡å‹
loaded_model = joblib.load(model_save_path)
print("æ¨¡å‹å·²æˆåŠŸè¼‰å…¥")
#lx=process_video_and_predict(video_path, loaded_model)


